import { NextRequest, NextResponse } from 'next/server'
import { OpenAICompatibleClient } from '@/lib/openai-client'

export async function POST(request: NextRequest) {
  try {
    const { baseUrl, apiKey } = await request.json()

    // è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤APIè¢«è°ƒç”¨
    console.log("ğŸ”§ /api/models called for fetching model list")
    console.log("ğŸŒ Base URL:", baseUrl)

    if (!baseUrl || !apiKey) {
      return NextResponse.json({ 
        success: false, 
        error: "Base URL and API Key are required" 
      }, { status: 400 })
    }

    // âœ… æ³¨æ„ï¼šæ­¤APIç”¨äºè·å–ç§æœ‰é…ç½®çš„æ¨¡å‹åˆ—è¡¨ï¼Œä¸è¿›è¡ŒURLéªŒè¯
    // âœ… ç§æœ‰é…ç½®å…è®¸ç”¨æˆ·ä½¿ç”¨ä»»ä½•URLï¼ŒåŒ…æ‹¬å®˜æ–¹API
    // ğŸš« åªæœ‰å…±äº«æœåŠ¡(/api/shared-keys/*)æ‰éœ€è¦URLéªŒè¯
    console.log("âœ… Private config model fetch - URL validation SKIPPED")

    // åˆ›å»ºå®¢æˆ·ç«¯
    const client = new OpenAICompatibleClient(baseUrl, apiKey)

    console.log("ğŸš€ Fetching models from:", baseUrl)
    
    // è·å–æ¨¡å‹åˆ—è¡¨
    const result = await client.listModels()
    
    console.log("âœ… Models fetched successfully, count:", result.data?.length || 0)

    return NextResponse.json({
      success: true,
      models: result.data || [],
      message: `Successfully fetched ${result.data?.length || 0} models`
    })

  } catch (error) {
    console.error("âŒ Models fetch error:", error)
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯URLéªŒè¯é”™è¯¯
    if (error instanceof Error && error.message.includes("å°ç¦")) {
      console.error("ğŸš¨ UNEXPECTED: URL validation error in private config model fetch!")
      console.error("ğŸš¨ This should NOT happen - private configs should allow any URL")
    }

    // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    let errorMessage = "Failed to fetch models"
    if (error instanceof Error) {
      if (error.message.includes("è·å–æ¨¡å‹åˆ—è¡¨è¶…æ—¶")) {
        errorMessage = "è¯·æ±‚è¶…æ—¶ï¼šAPIæœåŠ¡å“åº”æ—¶é—´è¿‡é•¿ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
      } else if (error.message.includes("ç½‘ç»œè¿æ¥å¤±è´¥")) {
        errorMessage = "ç½‘ç»œè¿æ¥å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°APIæœåŠ¡ï¼Œè¯·æ£€æŸ¥URLå’Œç½‘ç»œè¿æ¥"
      } else if (error.message.includes("Failed to fetch models")) {
        errorMessage = "APIè°ƒç”¨å¤±è´¥ï¼šè¯·æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®ï¼Œæˆ–APIæœåŠ¡æ˜¯å¦å¯ç”¨"
      } else {
        errorMessage = error.message
      }
    }

    return NextResponse.json({
      success: false,
      error: errorMessage,
      details: error instanceof Error ? error.message : String(error)
    }, { status: 500 })
  }
}

// GETæ–¹æ³•ç”¨äºAPIæ–‡æ¡£
export async function GET() {
  return NextResponse.json({
    message: 'Models API',
    description: 'Fetch available models from AI API endpoints',
    usage: 'POST with { "baseUrl": "https://api.example.com", "apiKey": "your-key" }',
    note: 'This API is for private configurations and does not perform URL validation'
  })
}
